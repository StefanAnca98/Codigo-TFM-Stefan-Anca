{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d3e8ae-8ede-4c46-bff7-68d586e269d7",
   "metadata": {},
   "source": [
    "**Carga de datos usados para la descarga**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b08ca-7c15-44ba-b575-c3d0059e2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manualmente cargamos el archivo csv correspondiente a la búsqueda de videos que queremos usar para descargar comentarios\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"busquedas/terms_pseudo/camuflated_pseudoscientific.csv\")\n",
    "data = data[data['Content_Classification'] == 'Pseudocientífico\\n']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f663f8b-05c5-4cc1-87b9-3c84b4f6aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_videos = data.iloc[:, 0]\n",
    "lista_videos_inicial = lista_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81210b3f-7396-4772-b939-aab6c100ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43192d-0582-486b-8f64-d70de5a915fb",
   "metadata": {},
   "source": [
    "**Configuración API YouTube**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de94dc3-2d7e-4240-9303-d1e97f4b4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from googleapiclient.discovery import build\n",
    "import googleapiclient.discovery\n",
    "api_key = ''\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebdf4e-cab7-4fe9-9042-55261aef55ac",
   "metadata": {},
   "source": [
    "**Función para descargar todos los comentarios de cada vídeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143c68f-32ea-4e13-8e34-955a7c89dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to extract the comments of a video\n",
    "\n",
    "import time\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "# Function to retrieve comments from a YouTube video\n",
    "def retrieve_comments(video_id):\n",
    "    comments_data = []  # List to store comments and related data\n",
    "    next_page_token = None  # Token for paginated API responses\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Construct a request to retrieve comment threads for the video\n",
    "            comments_request = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                textFormat='plainText',\n",
    "                maxResults=100,  # Maximum number of comments per page\n",
    "                pageToken=next_page_token  # Use token for pagination\n",
    "            )\n",
    "            # Execute the comments request and store the response\n",
    "            comments_response = comments_request.execute()\n",
    "    \n",
    "            # Iterate through comments in the response\n",
    "            for item in comments_response['items']:\n",
    "                comment_snippet = item['snippet']['topLevelComment']['snippet']\n",
    "                comment_text = comment_snippet['textDisplay']  # Text of the comment\n",
    "                # comment_likes = comment_snippet['likeCount']  # Number of likes on the comment\n",
    "                comment_timestamp = comment_snippet['publishedAt']  # Timestamp of the comment\n",
    "                comment_id = item['id']\n",
    "    \n",
    "                replies_data = []  # List to store reply texts and their timestamps\n",
    "                # Construct a request to retrieve replies to the current comment\n",
    "                reply_request = youtube.comments().list(\n",
    "                    part='snippet',\n",
    "                    parentId=item['id'],  # ID of the current comment\n",
    "                    maxResults=100  # Maximum number of replies per page\n",
    "                )\n",
    "                # Execute the reply request and store the response\n",
    "                reply_response = reply_request.execute()\n",
    "    \n",
    "                # Iterate through replies in the response\n",
    "                for reply_item in reply_response['items']:\n",
    "                    reply_text = reply_item['snippet']['textDisplay']\n",
    "                    # reply_likes = reply_item['likeCount']  # Number of likes\n",
    "                    reply_timestamp = reply_item['snippet']['publishedAt']  # Timestamp of the reply\n",
    "                    replies_data.append({\n",
    "                        'reply_id': reply_item['id'],\n",
    "                        'reply': reply_text,\n",
    "                        # 'likes': reply_likes,\n",
    "                        'timestamp': reply_timestamp,\n",
    "                        \n",
    "                    })\n",
    "    \n",
    "                # Store comment data and related replies in the comments_data list\n",
    "                comments_data.append({\n",
    "                    'comment_id': comment_id,\n",
    "                    'comment': comment_text,\n",
    "                    # 'likes': comment_likes,\n",
    "                    'timestamp': comment_timestamp,\n",
    "                    'replies': replies_data\n",
    "                    \n",
    "                })\n",
    "    \n",
    "            # Retrieve the next page token from the response\n",
    "            next_page_token = comments_response.get('nextPageToken')\n",
    "            # Break the loop if there are no more pages or a maximum of 500 comments are retrieved\n",
    "            if not next_page_token or len(comments_data) >= 500:\n",
    "                break\n",
    "    \n",
    "            time.sleep(2)  # Add a delay between API requests to avoid rate limits\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    return comments_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3591b-6c56-454a-9847-1b147bad49f8",
   "metadata": {},
   "source": [
    "**Descargar los vídeos de una lista dada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bf135-1824-45e6-8b51-320d83074f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Using the function with all the selected videos\n",
    "dict_video_comments = {}\n",
    "i = 0\n",
    "for video_id in lista_videos:\n",
    "#for video_id in dict_respuestas_llm_filtrado.keys():\n",
    "    comments_of_the_video = retrieve_comments(video_id)\n",
    "    comments_with_timestamps = []\n",
    "    for comment in comments_of_the_video:\n",
    "        comments_with_timestamps.append({\n",
    "        'comment_id':comment['comment_id'],\n",
    "        'comment': comment['comment'].strip(),\n",
    "        'timestamp': comment['timestamp'],\n",
    "        'is_response': 'False',\n",
    "        'response_of': \"NA\"\n",
    "    })\n",
    "        if comment['replies'] != []:\n",
    "            for reply in comment['replies']:\n",
    "                comments_with_timestamps.append({\n",
    "                    'comment_id': reply['reply_id'],\n",
    "                    'comment': reply['reply'].strip(),\n",
    "                    'timestamp': reply['timestamp'],\n",
    "                    'is_response': 'True',\n",
    "                    'response_of': comment['comment_id']\n",
    "                })\n",
    "    comments_with_timestamps = pd.DataFrame(comments_with_timestamps)\n",
    "    dict_video_comments[video_id] = comments_with_timestamps\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "dict_video_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d984530-9beb-4efd-b6bc-98655a727864",
   "metadata": {},
   "source": [
    "**Combinamos todos los dataframes en uno solo y mantenemos solo los hilos de conversaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa9a32-9f9c-411f-b662-df8a928ba6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartamos los dataframes vacíos\n",
    "dict_video_comments = {\n",
    "    k: v for k, v in dict_video_comments.items() if not v.empty\n",
    "}\n",
    "\n",
    "# Creamos un identificador único para los registros de cada dataframe\n",
    "for video_id, df in dict_video_comments.items():\n",
    "    df['case_id'] = video_id\n",
    "    dict_video_comments[video_id] = df\n",
    "\n",
    "# Combinamos todos los dataframes en uno solo\n",
    "combined_df = pd.concat(dict_video_comments.values(), ignore_index=True)\n",
    "\n",
    "# Convertimos a 'timestamp' la columna timestamp\n",
    "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])\n",
    "\n",
    "# Extraemos todos los comment_id que fueron referenciados como 'response_of' (es decir, son roots reales de hilos)\n",
    "roots_ids = combined_df['response_of'].dropna().unique()\n",
    "\n",
    "# Función con la que asignamos un ID indicando a que conversación pertenece cada comentario\n",
    "def assign_conversation_id(row):\n",
    "    if row['comment_id'] in roots_ids:\n",
    "        return row['comment_id']  # Este es el root de un hilo\n",
    "    elif pd.notna(row['response_of']) and row['response_of'] in roots_ids:\n",
    "        return row['response_of']  # Este es parte de un hilo\n",
    "    else:\n",
    "        return None  # Comentario aislado\n",
    "# Aplicamos la función a todos los casos\n",
    "combined_df['conversation_id'] = combined_df.apply(assign_conversation_id, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Eliminamos los comentarios aislados (sin conversation_id)\n",
    "combined_df = combined_df[combined_df['conversation_id'] != 'NA']\n",
    "\n",
    "# Contamos comentarios por conversación\n",
    "conversation_sizes = combined_df['conversation_id'].value_counts()\n",
    "valid_conversations = conversation_sizes[conversation_sizes > 1].index\n",
    "\n",
    "# Filtramos solo las conversaciones útiles\n",
    "combined_df = combined_df[combined_df['conversation_id'].isin(valid_conversations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec48afd-6d14-4faf-bccf-dcb0ed27cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b8b0e-2a43-4711-9055-62fbfab8171a",
   "metadata": {},
   "source": [
    "**Detección de vídeos en los que no se han descargado los comentarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba682c-adda-47ec-b97a-24f573ae9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_descargada=list(dict_video_comments.keys())\n",
    "lista_videos = set(lista_videos)  # Convertimos a conjunto\n",
    "lista_descargada = set(lista_descargada)  # Convertimos a conjunto\n",
    "\n",
    "lista_faltante = lista_videos - lista_descargada\n",
    "lista_faltante = list(lista_videos - lista_descargada)\n",
    "lista_faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf6bf4-8614-43dd-b2c9-0d721c0aee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_videos=lista_faltante\n",
    "len(lista_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e119b-e5bc-4ecc-b52e-2b6a51a92ebf",
   "metadata": {},
   "source": [
    "**Exportamos a CSV el resultado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846ba86-9e1c-4686-8444-50894dc0d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"Comentarios_camuflated_pseudoscientific.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ece02-6103-4abb-a0a2-b70c254817a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
